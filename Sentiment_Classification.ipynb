{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "deae2746",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from datasets import load_dataset\n",
        "# import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "import numpy as np\n",
        "import evaluate\n",
        "# import heapq\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import defaultdict\n",
        "import sys\n",
        "from typing import List\n",
        "\n",
        "# Add project root to Python path\n",
        "repo_root = Path(\".\").resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "\n",
        "# Remove cached modules to force a fresh import\n",
        "for mod in list(sys.modules.keys()):\n",
        "    if mod.startswith(\"utils.\") or mod.startswith(\"sparse_autoencoder.\"):\n",
        "        del sys.modules[mod]\n",
        "\n",
        "import utils.finbert\n",
        "import utils.analysis\n",
        "import utils.ablation\n",
        "import utils.run_dirs\n",
        "import sparse_autoencoder.finbert_sae\n",
        "import utils.data_cleaning\n",
        "\n",
        "from utils.finbert import compute_metrics\n",
        "from utils.analysis import (\n",
        "    FeatureStatsAggregator,\n",
        "    FeatureTopTokenTracker,\n",
        "    HeadlineFeatureAggregator\n",
        ")\n",
        "from utils.ablation import (\n",
        "    create_intervention_hook,\n",
        "    validate_feature_ids,\n",
        "    normalize_decoder_weights,\n",
        "    expand_features_with_similarity,\n",
        "    run_baseline_inference,\n",
        "    run_ablation_inference,\n",
        "    find_flipped_predictions,\n",
        ")\n",
        "from utils.run_dirs import make_analysis_run_dir\n",
        "from sparse_autoencoder.finbert_sae import SparseAutoencoder, load_sae\n",
        "from utils.data_cleaning import clean_text, remove_leading_tickers\n",
        "\n",
        "# --------- CUDA sanity check ----------\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Define device for SAE loading\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "31a1b31e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Load dataset, comes with train and validation fold \n",
        "ds = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
        "\n",
        "\n",
        "# Clean dataset\n",
        "ds = ds.map(lambda x: {\"text\": clean_text(x[\"text\"])})\n",
        "ds = ds.map(lambda x: {\"text\": remove_leading_tickers(x[\"text\"])})\n",
        "\n",
        "# Load dataset\n",
        "train_ds = ds[\"train\"]\n",
        "test_ds = ds[\"validation\"]  # Use validation set for analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8034bf6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constants/Hyperparameters for training model and SAE\n",
        "LAYER_TO_EXTRACT = 8  # 3/4 layer of BERT (0-11 for base BERT)\n",
        "LATENT_DIMS = [4096, 8192, 16384, 32768]  # Train SAEs with 4k, 8k, 16k, 32k features\n",
        "L1_COEFFICIENT = 1e-3  # Sparsity penalty\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "\n",
        "# Configuration for Inference\n",
        "MAX_SAMPLES = 100  # Limit for testing\n",
        "TOP_FEATURES = 100  # Top features to track per metric\n",
        "TOP_TOKENS_PER_FEATURE = 20  # Top activating tokens per feature\n",
        "MAX_SEQ_LENGTH = 64  # Maximum sequence length to process\n",
        "SAE_SIZE = \"32k\"  # <-- Change this to switch between SAE models, Choose which SAE to use: \"4k\", \"8k\", \"16k\", or \"32k\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f233625a",
      "metadata": {},
      "source": [
        "Fine Tune Hyperparameters of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f40e9d6",
      "metadata": {},
      "source": [
        "This trains an SAE to decompose FinBERT's 768-dimensional activations into ~4k to 32k interpretable sparse features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c951276",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell finetunes SAEs based on BERT.\n",
        "# Configuration\n",
        "LAYER_TO_EXTRACT = 8  # Middle layer of BERT\n",
        "LATENT_DIMS = [4096, 8192, 16384, 32768]  # Train SAEs with 4k, 8k, 16k, 32k features\n",
        "L1_COEFFICIENT = 1e-3  # Sparsity penalty\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "# Create SAE save directory\n",
        "Path(\"./finbert_sae\").mkdir(exist_ok=True)\n",
        "\n",
        "# Load the fine-tuned model\n",
        "save_dir = \"./finbert_twitter_ft/best\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load dataset\n",
        "# train_ds = ds[\"train\"]\n",
        "\n",
        "print(f\"Collecting activations from {len(train_ds)} training samples...\")\n",
        "print(f\"Target layer: {LAYER_TO_EXTRACT}\")\n",
        "print(f\"Will train SAEs with latent dimensions: {LATENT_DIMS}\")\n",
        "\n",
        "# Collect training activations\n",
        "all_activations = []\n",
        "captured_activations = []\n",
        "\n",
        "def capture_hook(module, input, output):\n",
        "    if isinstance(output, tuple):\n",
        "        hidden_states = output[0]\n",
        "    else:\n",
        "        hidden_states = output\n",
        "    captured_activations.append(hidden_states.detach())  # Keep on GPU\n",
        "\n",
        "# Register hook\n",
        "target_layer = model.bert.encoder.layer[LAYER_TO_EXTRACT]\n",
        "hook_handle = target_layer.register_forward_hook(capture_hook)\n",
        "\n",
        "# Collect activations from all training data\n",
        "print(\"Extracting activations from training set...\")\n",
        "print(\"Filtering out ALL special tokens (CLS, SEP, PAD, UNK, MASK, etc.) - keeping only content tokens...\")\n",
        "with torch.no_grad():\n",
        "    for idx, sample in enumerate(tqdm(train_ds)):\n",
        "        text = sample[\"text\"]\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=64)\n",
        "        inputs = inputs.to(device)\n",
        "        \n",
        "        captured_activations.clear()\n",
        "        _ = model(**inputs)\n",
        "        \n",
        "        if captured_activations:\n",
        "            # Get all token activations: [seq_len, 768] - stays on GPU\n",
        "            activation = captured_activations[0].squeeze(0)\n",
        "            \n",
        "            # Get attention mask and token IDs (keep on GPU)\n",
        "            attention_mask = inputs[\"attention_mask\"].squeeze(0).bool()\n",
        "            token_ids = inputs[\"input_ids\"].squeeze(0)\n",
        "            \n",
        "            # Filter out ALL special tokens (CLS, SEP, PAD, UNK, MASK, etc.)\n",
        "            special_ids = set(tokenizer.all_special_ids)\n",
        "            not_special = torch.tensor([tid.item() not in special_ids for tid in token_ids], \n",
        "                                       dtype=torch.bool, device=device)\n",
        "            \n",
        "            valid_mask = attention_mask & not_special  # GPU boolean mask\n",
        "\n",
        "            # Print the number of valid tokens\n",
        "            # kept = valid_mask.sum().item()\n",
        "            # total = attention_mask.sum().item()\n",
        "            # print(f\"Kept {kept}/{total} tokens\")\n",
        "\n",
        "            # tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "            # kept_tokens = [t for t, m in zip(tokens, valid_mask.tolist()) if m]\n",
        "            # dropped_tokens = [t for t, m in zip(tokens, valid_mask.tolist()) if not m]\n",
        "\n",
        "            # print(\"TOKENS:\", tokens)\n",
        "            # print(\"DROPPED:\", dropped_tokens)\n",
        "            # print(\"KEPT:\", kept_tokens)\n",
        "            \n",
        "            # Only keep activations for real content tokens (still on GPU)\n",
        "            activation = activation[valid_mask]\n",
        "            \n",
        "            # Only add if there are real tokens\n",
        "            if activation.shape[0] > 0:\n",
        "                # Move to CPU only when storing for later processing\n",
        "                all_activations.append(activation.cpu())\n",
        "\n",
        "hook_handle.remove()\n",
        "\n",
        "# Flatten all activations into a single tensor [total_tokens, 768]\n",
        "all_activations_tensor = torch.cat(all_activations, dim=0)\n",
        "print(f\"\\\\nCollected {all_activations_tensor.shape[0]} token activations\")\n",
        "print(f\"Activation shape: {all_activations_tensor.shape}\")\n",
        "\n",
        "# Train SAEs for each latent dimension\n",
        "for LATENT_DIM in LATENT_DIMS:\n",
        "    print(f\"\\\\n{'='*80}\")\n",
        "    print(f\"Training SAE with {LATENT_DIM} latent features ({LATENT_DIM//1024}k)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # Create SAE\n",
        "    sae = SparseAutoencoder(input_dim=768, latent_dim=LATENT_DIM)\n",
        "    sae.to(device)\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(sae.parameters(), lr=LEARNING_RATE)\n",
        "    \n",
        "    # Create DataLoader\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "    dataset = TensorDataset(all_activations_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    \n",
        "    # Training loop\n",
        "    print(f\"\\\\nTraining SAE for {NUM_EPOCHS} epochs...\")\n",
        "    sae.train()\n",
        "    \n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        total_loss = 0\n",
        "        total_recon_loss = 0\n",
        "        total_l1_loss = 0\n",
        "        \n",
        "        for batch_idx, (batch_x,) in enumerate(dataloader):\n",
        "            batch_x = batch_x.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            reconstruction, latent = sae(batch_x)\n",
        "            \n",
        "            # Reconstruction loss (MSE)\n",
        "            recon_loss = nn.functional.mse_loss(reconstruction, batch_x)\n",
        "            \n",
        "            # L1 sparsity loss\n",
        "            l1_loss = latent.abs().mean()\n",
        "            \n",
        "            # Combined loss\n",
        "            loss = recon_loss + L1_COEFFICIENT * l1_loss\n",
        "            \n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Renormalize decoder weights (standard SAE practice)\n",
        "            with torch.no_grad():\n",
        "                sae.decoder.weight.data = nn.functional.normalize(\n",
        "                    sae.decoder.weight.data, dim=0\n",
        "                )\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            total_recon_loss += recon_loss.item()\n",
        "            total_l1_loss += l1_loss.item()\n",
        "        \n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        avg_recon = total_recon_loss / len(dataloader)\n",
        "        avg_l1 = total_l1_loss / len(dataloader)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}: Loss={avg_loss:.4f}, \"\n",
        "              f\"Recon={avg_recon:.4f}, L1={avg_l1:.4f}\")\n",
        "    \n",
        "    # Save the trained SAE\n",
        "    SAE_SAVE_PATH = f\"./finbert_sae/layer_{LAYER_TO_EXTRACT}_{LATENT_DIM//1024}k.pt\"\n",
        "    print(f\"\\\\nSaving trained SAE to {SAE_SAVE_PATH}\")\n",
        "    torch.save({\n",
        "        'encoder_weight': sae.encoder.weight.data.cpu(),\n",
        "        'encoder_bias': sae.encoder.bias.data.cpu(),\n",
        "        'decoder_weight': sae.decoder.weight.data.cpu(),\n",
        "        'decoder_bias': sae.decoder.bias.data.cpu(),\n",
        "        'config': {\n",
        "            'input_dim': 768,\n",
        "            'latent_dim': LATENT_DIM,\n",
        "            'layer': LAYER_TO_EXTRACT,\n",
        "            'model': save_dir,\n",
        "        }\n",
        "    }, SAE_SAVE_PATH)\n",
        "    \n",
        "    # Test sparsity\n",
        "    sae.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_acts = all_activations_tensor[:1000].to(device)\n",
        "        sample_latent = sae.encode(sample_acts)\n",
        "        sparsity = (sample_latent > 0).float().mean()\n",
        "        print(f\"\\\\n‚úì SAE trained successfully!\")\n",
        "        print(f\"  Average sparsity: {sparsity:.2%} of features active\")\n",
        "        print(f\"  Saved to: {SAE_SAVE_PATH}\")\n",
        "\n",
        "print(f\"\\\\n{'='*80}\")\n",
        "print(f\"All SAEs trained successfully!\")\n",
        "print(f\"Available SAE models:\")\n",
        "for dim in LATENT_DIMS:\n",
        "    print(f\"  - layer_{LAYER_TO_EXTRACT}_{dim//1024}k.pt ({dim} features)\")\n",
        "print(f\"\\\\nThese SAEs can now be used in main.py for interpretability analysis!\")\n",
        "print(f\"{'='*80}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d70e94b",
      "metadata": {},
      "source": [
        "Finetune FinBERT Model\n",
        "\n",
        "The FinBERT model is trained on the training fold of our dataset to improve its prediction accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0697b2e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell finetunes the FINBERT model.\n",
        "\n",
        "# 2) Load model/tokenizer\n",
        "model_name = \"ahmedrachid/FinancialBERT-Sentiment-Analysis\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "id2label = {0: \"Bearish\", 1: \"Bullish\", 2: \"Neutral\"}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# Move model to GPU\n",
        "model.to(device)\n",
        "\n",
        "# 3) Tokenize\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True)\n",
        "\n",
        "train_tok = train_ds.map(tokenize_fn, batched=True)\n",
        "val_tok = test_ds.map(tokenize_fn, batched=True)\n",
        "\n",
        "train_tok = train_tok.rename_column(\"label\", \"labels\")\n",
        "val_tok = val_tok.rename_column(\"label\", \"labels\")\n",
        "\n",
        "cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "train_tok.set_format(type=\"torch\", columns=cols_to_keep)\n",
        "val_tok.set_format(type=\"torch\", columns=cols_to_keep)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# 4) Metrics\n",
        "acc = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "# 5) Training config\n",
        "use_fp16 = torch.cuda.is_available()  # fp16 only makes sense on GPU\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finbert_twitter_ft\",\n",
        "    eval_strategy=\"epoch\",   # <-- use this name; some versions don't accept eval_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    fp16=use_fp16,                 # <-- enables mixed precision on NVIDIA GPU\n",
        "    dataloader_num_workers=0,      # safer on Windows; avoids hanging\n",
        "    report_to=\"none\",              # avoids needing wandb, etc.\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "\n",
        "trainer.save_model(\"./finbert_twitter_ft/best\")\n",
        "tokenizer.save_pretrained(\"./finbert_twitter_ft/best\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f30b519",
      "metadata": {},
      "source": [
        "Inference with Interpretability\n",
        "\n",
        "We use our FinBERT + SAE on test data. We extract a Layer Activations with Sentiment Predictions (SAE-style Analysis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a64315a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FEATURE ABLATION EXPERIMENT\n",
            "============================================================\n",
            "Ablation Mode: manual\n",
            "Similarity Expansion: False\n",
            "‚úì Loaded SAE from ./finbert_sae/layer_8_32k.pt\n",
            "  Layer: 8\n",
            "  Input dim: 768\n",
            "  Latent dim: 32768\n",
            "Ablation mode: manual\n",
            "Layer: 8\n",
            "SAE Size: 32k (32768 features)\n",
            "Max Samples: 100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Feature Ablation Experiment\n",
        "# This cell performs ablation by zeroing out specified SAE features and comparing predictions\n",
        "\n",
        "# Configuration\n",
        "# ========== ABLATION CONFIGURATION ==========\n",
        "ABLATION_CONFIG = {\n",
        "    \n",
        "    \"mode\": \"manual\",                 # Mode 1, Options: \"manual\" | \"per_sample_top_k\" | \"union_top_k\"\n",
        "    #\"mode\": \"per_sample_top_k\",       # Mode 2\n",
        "    #\"mode\": \"union_top_k\",             # Mode 3\n",
        "    \"k\": 10,                           # Only for per_sample_top_k and union_top_k modes\n",
        "    \"skip_sae_reconstruction\": False,  # If True, skip SAE hook entirely (true baseline)\n",
        "    \"similarity_expansion\": False,      # If True, include top m similar features to selected features\n",
        "    \"similarity_top_m\": 64            # Total features per seed feature (includes original)\n",
        "}\n",
        "\n",
        "# Mode 1: Manual features (only used if mode == \"manual\")\n",
        "#MANUAL_FEATURES = [4456, 21508, 21969, 27518, 21110, 24583, 32601, 15959, 27518, 29555, 3993, 13142, 22354, 21858]\n",
        "# MANUAL_FEATURES = [21110, 24583, 21508, 32601, 15959, 27518, 29555, 3993, 13142, 22354] # row 0 true top 10\n",
        "MANUAL_FEATURES = [21508, 27518]\n",
        "#MANUAL_FEATURES = []\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FEATURE ABLATION EXPERIMENT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Ablation Mode: {ABLATION_CONFIG['mode']}\")\n",
        "if ABLATION_CONFIG['mode'] != 'manual':\n",
        "    print(f\"K value: {ABLATION_CONFIG['k']}\")\n",
        "print(f\"Similarity Expansion: {ABLATION_CONFIG['similarity_expansion']}\")\n",
        "if ABLATION_CONFIG['similarity_expansion']:\n",
        "    print(f\"Similarity Top-M: {ABLATION_CONFIG['similarity_top_m']}\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "save_dir = \"./finbert_twitter_ft/best\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "\n",
        "# Define device and move model to it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu only, please install CUDA-compatible Torch\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load the SAE using the helper function\n",
        "sae, sae_config = load_sae(layer=LAYER_TO_EXTRACT, latent_size=SAE_SIZE)\n",
        "\n",
        "# Extract dimensions from the loaded config\n",
        "SAE_INPUT_DIM = sae_config['input_dim']\n",
        "SAE_LATENT_DIM = sae_config['latent_dim']\n",
        "\n",
        "print(f\"Ablation mode: {ABLATION_CONFIG['mode']}\")\n",
        "print(f\"Layer: {LAYER_TO_EXTRACT}\")\n",
        "print(f\"SAE Size: {SAE_SIZE} ({SAE_LATENT_DIM} features)\")\n",
        "print(f\"Max Samples: {MAX_SAMPLES}\\n\")\n",
        "\n",
        "# Storage for results\n",
        "baseline_predictions = []\n",
        "ablated_predictions = []\n",
        "sample_data = []\n",
        "\n",
        "# Initialize trackers for SAE features (same as inference cell)\n",
        "feature_stats_ablated = FeatureStatsAggregator(SAE_LATENT_DIM)\n",
        "top_token_tracker_ablated = FeatureTopTokenTracker(SAE_LATENT_DIM, TOP_TOKENS_PER_FEATURE)\n",
        "headline_aggregator_ablated = HeadlineFeatureAggregator(top_k=10)\n",
        "all_prompt_metadata_ablated = []\n",
        "\n",
        "# Storage for capturing SAE features during ablation (for tracking)\n",
        "current_sample_data = {\"sae_features\": None, \"token_ids\": None, \"prompt_tokens\": None, \"text\": None, \"idx\": None}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cac4bc40",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ Running baseline inference (no ablation)...\n",
            "  Baseline: 20/100 samples\n",
            "  Baseline: 40/100 samples\n",
            "  Baseline: 60/100 samples\n",
            "  Baseline: 80/100 samples\n",
            "  Baseline: 100/100 samples\n",
            "‚úì Baseline accuracy: 87.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Baseline Inference\n",
        "print(\"üî¨ Running baseline inference (no ablation)...\")\n",
        "baseline_results, baseline_features_map, baseline_accuracy = run_baseline_inference(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_ds=test_ds,\n",
        "    device=device,\n",
        "    sae=sae,\n",
        "    layer_to_extract=LAYER_TO_EXTRACT,\n",
        "    max_samples=MAX_SAMPLES,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        ")\n",
        "print(f\"‚úì Baseline accuracy: {baseline_accuracy:.2%}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "760bf70f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mode 1 (Manual): Ablating 2 manually specified features\n",
            "Features to ablate: [21508, 27518]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Feature Selection & Expansion\n",
        "skip_hooks = ABLATION_CONFIG.get(\"skip_sae_reconstruction\", False)\n",
        "\n",
        "similarity_enabled = ABLATION_CONFIG.get(\"similarity_expansion\", False)\n",
        "similarity_top_m = int(ABLATION_CONFIG.get(\"similarity_top_m\", 10))\n",
        "if similarity_top_m < 1:\n",
        "    raise ValueError(\"similarity_top_m must be >= 1\")\n",
        "\n",
        "normalized_decoder = None\n",
        "similarity_cache = {}\n",
        "if similarity_enabled and not skip_hooks:\n",
        "    normalized_decoder = normalize_decoder_weights(sae, device)\n",
        "    print(f\"Similarity expansion: enabled (top_m={similarity_top_m})\")\n",
        "elif similarity_enabled and skip_hooks:\n",
        "    print(\"Similarity expansion requested, but skip_sae_reconstruction=True; expansion disabled.\")\n",
        "    similarity_enabled = False\n",
        "\n",
        "if skip_hooks:\n",
        "    print(\"\\n‚ÑπÔ∏è Skipping SAE reconstruction (true baseline mode)\")\n",
        "    print(\"   Predictions will match baseline exactly\\n\")\n",
        "    FEATURES_TO_ABLATE = None\n",
        "    ORIGINAL_SEED_FEATURES = None\n",
        "else:\n",
        "    ORIGINAL_SEED_FEATURES = None\n",
        "\n",
        "    if ABLATION_CONFIG[\"mode\"] == \"manual\":\n",
        "        FEATURES_TO_ABLATE = MANUAL_FEATURES\n",
        "        ORIGINAL_SEED_FEATURES = list(MANUAL_FEATURES)\n",
        "        validate_feature_ids(FEATURES_TO_ABLATE, SAE_LATENT_DIM, \"manual features\")\n",
        "        original_feature_count = len(FEATURES_TO_ABLATE)\n",
        "        if similarity_enabled:\n",
        "            FEATURES_TO_ABLATE = expand_features_with_similarity(\n",
        "                FEATURES_TO_ABLATE, normalized_decoder, similarity_top_m, similarity_cache\n",
        "            )\n",
        "        print(f\"\\nMode 1 (Manual): Ablating {len(FEATURES_TO_ABLATE)} manually specified features\")\n",
        "        if similarity_enabled:\n",
        "            print(f\"  Similarity expansion: {original_feature_count} ‚Üí {len(FEATURES_TO_ABLATE)} (top_m={similarity_top_m})\")\n",
        "    elif ABLATION_CONFIG[\"mode\"] == \"union_top_k\":\n",
        "        feature_set = set()\n",
        "        for idx in baseline_features_map:\n",
        "            top_k_ids = [f[\"feature_id\"] for f in baseline_features_map[idx][\"top_features\"][:ABLATION_CONFIG[\"k\"]]]\n",
        "            feature_set.update(top_k_ids)\n",
        "        FEATURES_TO_ABLATE = sorted(list(feature_set))\n",
        "        validate_feature_ids(FEATURES_TO_ABLATE, SAE_LATENT_DIM, \"union_top_k features\")\n",
        "        original_feature_count = len(FEATURES_TO_ABLATE)\n",
        "        if similarity_enabled:\n",
        "            FEATURES_TO_ABLATE = expand_features_with_similarity(\n",
        "                FEATURES_TO_ABLATE, normalized_decoder, similarity_top_m, similarity_cache\n",
        "            )\n",
        "        print(f\"\\nMode 3 (Union Top-K): Collected {len(FEATURES_TO_ABLATE)} unique features from union of top-{ABLATION_CONFIG['k']} across {len(baseline_results)} samples\")\n",
        "        if similarity_enabled:\n",
        "            print(f\"  Similarity expansion: {original_feature_count} ‚Üí {len(FEATURES_TO_ABLATE)} (top_m={similarity_top_m})\")\n",
        "    elif ABLATION_CONFIG[\"mode\"] == \"per_sample_top_k\":\n",
        "        FEATURES_TO_ABLATE = None\n",
        "        print(f\"\\nMode 2 (Per-Sample Top-K): Will ablate top-{ABLATION_CONFIG['k']} features individually for each sample\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown ablation mode: {ABLATION_CONFIG['mode']}\")\n",
        "\n",
        "    if ABLATION_CONFIG[\"mode\"] != \"per_sample_top_k\":\n",
        "        validate_feature_ids(FEATURES_TO_ABLATE, SAE_LATENT_DIM, \"global ablation features\")\n",
        "\n",
        "    if ABLATION_CONFIG[\"mode\"] == \"manual\":\n",
        "        print(f\"Features to ablate: {FEATURES_TO_ABLATE if FEATURES_TO_ABLATE is not None else 'Per-sample dynamic'}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a1d3f4f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ Running ablation inference (features zeroed)...\n",
            "  Ablated: 20/100 samples\n",
            "  Ablated: 40/100 samples\n",
            "  Ablated: 60/100 samples\n",
            "  Ablated: 80/100 samples\n",
            "  Ablated: 100/100 samples\n",
            "‚úì Ablated accuracy: 88.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ablation Inference\n",
        "print(\"üî¨ Running ablation inference (features zeroed)...\")\n",
        "(\n",
        "    ablated_results,\n",
        "    all_prompt_metadata_ablated,\n",
        "    similarity_stats,\n",
        "    all_ablated_features_set,\n",
        "    ablated_accuracy,\n",
        ") = run_ablation_inference(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_ds=test_ds,\n",
        "    device=device,\n",
        "    sae=sae,\n",
        "    layer_to_extract=LAYER_TO_EXTRACT,\n",
        "    max_samples=MAX_SAMPLES,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    ablation_config=ABLATION_CONFIG,\n",
        "    features_to_ablate=FEATURES_TO_ABLATE,\n",
        "    baseline_results=baseline_results,\n",
        "    baseline_features_map=baseline_features_map,\n",
        "    feature_stats_ablated=feature_stats_ablated,\n",
        "    top_token_tracker_ablated=top_token_tracker_ablated,\n",
        "    headline_aggregator_ablated=headline_aggregator_ablated,\n",
        "    current_sample_data=current_sample_data,\n",
        "    similarity_enabled=similarity_enabled,\n",
        "    normalized_decoder=normalized_decoder,\n",
        "    similarity_top_m=similarity_top_m,\n",
        "    similarity_cache=similarity_cache,\n",
        ")\n",
        "print(f\"‚úì Ablated accuracy: {ablated_accuracy:.2%}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "57981356",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FEATURE ABLATION RESULTS\n",
            "============================================================\n",
            "Ablation Mode: manual\n",
            "Seed Features: [21508, 27518]\n",
            "Total Features Ablated: 2\n",
            "Baseline Accuracy: 87.00%\n",
            "Ablated Accuracy: 88.00%\n",
            "Accuracy Change: 1.00%\n",
            "\n",
            "Flipped Predictions: 3/100 samples\n",
            "Flip Rate: 3.00%\n",
            "\n",
            "============================================================\n",
            "FLIPPED PREDICTIONS (showing first 3):\n",
            "============================================================\n",
            "\n",
            "--- Sample #5 ---\n",
            "Text: Barclays cools on Molson Coors\n",
            "True Label: Bearish\n",
            "Original: Bearish (conf: 0.648) ‚Üí Ablated: Neutral (conf: 0.452)\n",
            "Top 10 SAE Features:\n",
            "  Feature 4456: 8.8932\n",
            "  Feature 32601: 6.1672\n",
            "  Feature 15991: 4.6884\n",
            "  Feature 21508: 4.4652 [ABLATED]\n",
            "  Feature 29952: 4.4536\n",
            "  Feature 5111: 4.2631\n",
            "  Feature 28660: 4.2182\n",
            "  Feature 7927: 4.2108\n",
            "  Feature 687: 4.1628\n",
            "  Feature 27757: 4.0974\n",
            "\n",
            "\n",
            "--- Sample #38 ---\n",
            "Text: Alliance Global Partners starts at Buy\n",
            "True Label: Bullish\n",
            "Original: Neutral (conf: 0.528) ‚Üí Ablated: Bullish (conf: 0.504)\n",
            "Top 10 SAE Features:\n",
            "  Feature 4456: 9.0261\n",
            "  Feature 21110: 6.6836\n",
            "  Feature 25797: 6.2264\n",
            "  Feature 24583: 4.7995\n",
            "  Feature 18425: 4.3438\n",
            "  Feature 687: 4.2223\n",
            "  Feature 9847: 3.8847\n",
            "  Feature 32411: 3.8798\n",
            "  Feature 18317: 3.8705\n",
            "  Feature 13142: 3.8668\n",
            "\n",
            "\n",
            "--- Sample #77 ---\n",
            "Text: Snap Analyst Projects 37% Revenue Growth In 2020\n",
            "True Label: Bullish\n",
            "Original: Bearish (conf: 0.677) ‚Üí Ablated: Bullish (conf: 0.700)\n",
            "Top 10 SAE Features:\n",
            "  Feature 21110: 7.8783\n",
            "  Feature 4456: 7.1909\n",
            "  Feature 25797: 5.5498\n",
            "  Feature 18317: 5.2954\n",
            "  Feature 25518: 5.1933\n",
            "  Feature 32601: 5.1514\n",
            "  Feature 13142: 5.0637\n",
            "  Feature 24583: 5.0035\n",
            "  Feature 6026: 4.9927\n",
            "  Feature 26260: 4.9678\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Results Analysis\n",
        "flipped_samples = find_flipped_predictions(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    sae=sae,\n",
        "    layer_to_extract=LAYER_TO_EXTRACT,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    baseline_results=baseline_results,\n",
        "    ablated_results=ablated_results,\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FEATURE ABLATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if skip_hooks is False:\n",
        "    print(f\"Ablation Mode: {ABLATION_CONFIG['mode']}\")\n",
        "\n",
        "    if ABLATION_CONFIG[\"mode\"] == \"manual\" and ORIGINAL_SEED_FEATURES is not None:\n",
        "        print(f\"Seed Features: {ORIGINAL_SEED_FEATURES}\")\n",
        "        print(f\"Total Features Ablated: {len(FEATURES_TO_ABLATE)}\")\n",
        "        if similarity_enabled and len(FEATURES_TO_ABLATE) != len(ORIGINAL_SEED_FEATURES):\n",
        "            print(f\"  (Expanded from {len(ORIGINAL_SEED_FEATURES)} seeds)\")\n",
        "\n",
        "    elif ABLATION_CONFIG[\"mode\"] == \"union_top_k\" and FEATURES_TO_ABLATE is not None:\n",
        "        print(f\"Total Features Ablated: {len(FEATURES_TO_ABLATE)}\")\n",
        "        if similarity_enabled:\n",
        "            print(\"  (After similarity expansion)\")\n",
        "\n",
        "    elif ABLATION_CONFIG[\"mode\"] == \"per_sample_top_k\":\n",
        "        print(f\"Per-Sample: top-{ABLATION_CONFIG['k']} features\")\n",
        "        if len(all_ablated_features_set) > 0:\n",
        "            print(f\"Unique Features Ablated: {len(all_ablated_features_set)} (across {len(ablated_results)} samples)\")\n",
        "            if similarity_stats[\"expanded_counts\"]:\n",
        "                avg_per_sample = float(np.mean(similarity_stats[\"expanded_counts\"]))\n",
        "                print(f\"Per-Sample Average: {avg_per_sample:.1f} features\")\n",
        "            else:\n",
        "                print(f\"Per-Sample Average: {ABLATION_CONFIG['k']} features\")\n",
        "\n",
        "print(f\"Baseline Accuracy: {baseline_accuracy:.2%}\")\n",
        "print(f\"Ablated Accuracy: {ablated_accuracy:.2%}\")\n",
        "print(f\"Accuracy Change: {(ablated_accuracy - baseline_accuracy):.2%}\")\n",
        "print(f\"\\nFlipped Predictions: {len(flipped_samples)}/{len(baseline_results)} samples\")\n",
        "print(f\"Flip Rate: {len(flipped_samples)/len(baseline_results):.2%}\\n\")\n",
        "\n",
        "if flipped_samples:\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"FLIPPED PREDICTIONS (showing first {min(10, len(flipped_samples))}):\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, flip in enumerate(flipped_samples[:10], 1):\n",
        "        print(f\"\\n--- Sample #{flip['sample_idx']} ---\")\n",
        "        print(f\"Text: {flip['text'][:120]}{'...' if len(flip['text']) > 120 else ''}\")\n",
        "        print(f\"True Label: {flip['true_label']}\")\n",
        "        print(f\"Original: {flip['baseline_pred']} (conf: {flip['baseline_conf']:.3f}) ‚Üí \"\n",
        "              f\"Ablated: {flip['ablated_pred']} (conf: {flip['ablated_conf']:.3f})\")\n",
        "\n",
        "        if flip['top_features']:\n",
        "            print(\"Top 10 SAE Features:\")\n",
        "            for feat in flip['top_features']:\n",
        "                ablated_marker = \" [ABLATED]\" if feat['ablated'] else \"\"\n",
        "                print(f\"  Feature {feat['feature_id']}: {feat['activation']:.4f}{ablated_marker}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"No predictions were flipped by ablating these features.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "06e4df4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üíæ Saving ablated results for visualization...\n",
            "üíæ Saving ablated results to: C:\\Users\\andre\\OneDrive - National University of Singapore\\Desktop\\FYP\\sparse_autoencoder_openai\\analysis_data\\2026-02-03T15-07-52_run-091\n",
            "\n",
            "‚úÖ Ablation experiment complete!\n",
            "   üìÅ Ablated results saved to: 2026-02-03T15-07-52_run-091\n",
            "   üéØ Ablated Accuracy: 88.00%\n",
            "   üî¢ Total tokens: 1542\n",
            "   ‚ú® SAE features: 32768\n",
            "\n",
            "üåê Start the viewer to see ablated results:\n",
            "   python viz_analysis/feature_probe_server.py\n",
            "   cd sae-viewer && npm start\n"
          ]
        }
      ],
      "source": [
        "# Save Results\n",
        "print(\"\\nüíæ Saving ablated results for visualization...\")\n",
        "\n",
        "ablated_run_dir = make_analysis_run_dir(str(repo_root))\n",
        "print(f\"üíæ Saving ablated results to: {ablated_run_dir}\")\n",
        "\n",
        "stats_ablated = feature_stats_ablated.get_stats()\n",
        "\n",
        "top_features_by_metric_ablated = {}\n",
        "for metric_name, values in stats_ablated.items():\n",
        "    if metric_name == \"mean_act_squared\":\n",
        "        continue\n",
        "    top_indices = np.argsort(values)[-TOP_FEATURES:][::-1]\n",
        "    top_features_by_metric_ablated[metric_name] = [\n",
        "        {\n",
        "            \"feature_id\": int(idx),\n",
        "            \"value\": float(values[idx]),\n",
        "            \"metrics\": {\n",
        "                \"mean_activation\": float(stats_ablated[\"mean_activation\"][idx]),\n",
        "                \"max_activation\": float(stats_ablated[\"max_activation\"][idx]),\n",
        "                \"fraction_active\": float(stats_ablated[\"fraction_active\"][idx]),\n",
        "            },\n",
        "        }\n",
        "        for idx in top_indices\n",
        "    ]\n",
        "\n",
        "prompts_file = ablated_run_dir / \"prompts.jsonl\"\n",
        "with open(prompts_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for meta in all_prompt_metadata_ablated:\n",
        "        json.dump(meta, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "feature_stats_file = ablated_run_dir / \"feature_stats.json\"\n",
        "feature_stats_data = {\n",
        "    \"num_features\": SAE_LATENT_DIM,\n",
        "    \"total_tokens\": feature_stats_ablated.total_tokens,\n",
        "    \"top_feature_count\": TOP_FEATURES,\n",
        "    \"accuracy\": ablated_accuracy,\n",
        "    \"num_samples\": len(all_prompt_metadata_ablated),\n",
        "    \"mean_act_squared\": stats_ablated[\"mean_act_squared\"].tolist(),\n",
        "    \"metrics\": {\n",
        "        metric_name: {\n",
        "            \"description\": f\"{metric_name.replace('_', ' ').title()} for each feature\",\n",
        "            \"top_features\": top_features_by_metric_ablated[metric_name],\n",
        "        }\n",
        "        for metric_name in stats_ablated.keys() if metric_name != \"mean_act_squared\"\n",
        "    },\n",
        "}\n",
        "with open(feature_stats_file, \"w\") as f:\n",
        "    json.dump(feature_stats_data, f, indent=2)\n",
        "\n",
        "feature_tokens_file = ablated_run_dir / \"feature_tokens.json\"\n",
        "feature_tokens_data = {\"features\": top_token_tracker_ablated.export()}\n",
        "with open(feature_tokens_file, \"w\") as f:\n",
        "    json.dump(feature_tokens_data, f, indent=2)\n",
        "\n",
        "headline_features_file = ablated_run_dir / \"headline_features.json\"\n",
        "with open(headline_features_file, \"w\") as f:\n",
        "    json.dump(headline_aggregator_ablated.export(), f, indent=2)\n",
        "\n",
        "metadata_file = ablated_run_dir / \"metadata.json\"\n",
        "with open(metadata_file, \"w\") as f:\n",
        "    json.dump(\n",
        "        {\n",
        "            \"model\": save_dir,\n",
        "            \"layer_extracted\": LAYER_TO_EXTRACT,\n",
        "            \"num_samples\": len(all_prompt_metadata_ablated),\n",
        "            \"total_tokens\": feature_stats_ablated.total_tokens,\n",
        "            \"accuracy\": ablated_accuracy,\n",
        "            \"dataset\": \"zeroshot/twitter-financial-news-sentiment\",\n",
        "            \"split\": \"validation\",\n",
        "            \"hidden_dim\": SAE_INPUT_DIM,\n",
        "            \"latent_dim\": SAE_LATENT_DIM,\n",
        "            \"sae_path\": f\"./finbert_sae/layer_{LAYER_TO_EXTRACT}_{SAE_SIZE}.pt\",\n",
        "            \"top_features_per_metric\": TOP_FEATURES,\n",
        "            \"top_tokens_per_feature\": TOP_TOKENS_PER_FEATURE,\n",
        "            \"ablation_mode\": ABLATION_CONFIG[\"mode\"],\n",
        "            \"ablated_features\": FEATURES_TO_ABLATE if FEATURES_TO_ABLATE is not None else \"per_sample_dynamic\",\n",
        "            \"ablation_k\": ABLATION_CONFIG.get(\"k\"),\n",
        "            \"skip_sae_reconstruction\": ABLATION_CONFIG.get(\"skip_sae_reconstruction\", False),\n",
        "            \"similarity_expansion\": {\"enabled\": similarity_enabled, \"top_m\": similarity_top_m},\n",
        "            \"note\": f\"SAE sparse features with predictions (mode: {ABLATION_CONFIG['mode']})\",\n",
        "        },\n",
        "        f,\n",
        "        indent=2,\n",
        "    )\n",
        "\n",
        "print(\"\\n‚úÖ Ablation experiment complete!\")\n",
        "print(f\"   üìÅ Ablated results saved to: {ablated_run_dir.name}\")\n",
        "print(f\"   üéØ Ablated Accuracy: {ablated_accuracy:.2%}\")\n",
        "print(f\"   üî¢ Total tokens: {feature_stats_ablated.total_tokens}\")\n",
        "print(f\"   ‚ú® SAE features: {SAE_LATENT_DIM}\")\n",
        "print(\"\\nüåê Start the viewer to see ablated results:\")\n",
        "print(\"   python viz_analysis/feature_probe_server.py\")\n",
        "print(\"   cd sae-viewer && npm start\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def14c72",
      "metadata": {},
      "source": [
        "Testing Inference based on Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1de85884",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BULLISH  | TSLA beats earnings expectations and raises full-year guidance.\n",
            "BEARISH  | Apple shares fall after reporting weaker-than-expected iPhone sales.\n",
            "NEUTRAL  | The company reported results largely in line with analyst expectations.\n",
            "BEARISH  | Amazon warns of margin pressure due to rising logistics costs.\n",
            "BULLISH  | NVIDIA stock surges as demand for AI chips remains strong.\n",
            "BEARISH  | The firm announced a restructuring plan, sending shares lower.\n",
            "NEUTRAL  | Revenue growth slowed quarter-over-quarter, but profitability improved.\n",
            "NEUTRAL  | Investors remain cautious ahead of the Federal Reserve meeting.\n",
            "BULLISH  | Strong cash flow and reduced debt boosted investor confidence.\n",
            "BEARISH  | The outlook remains uncertain amid macroeconomic headwinds.\n"
          ]
        }
      ],
      "source": [
        "# Quick analysis on simple headlines\n",
        "save_dir = \"./finbert_twitter_ft/best\"\n",
        "\n",
        "example_sentences = [\n",
        "    \"TSLA beats earnings expectations and raises full-year guidance.\",\n",
        "    \"Apple shares fall after reporting weaker-than-expected iPhone sales.\",\n",
        "    \"The company reported results largely in line with analyst expectations.\",\n",
        "    \"Amazon warns of margin pressure due to rising logistics costs.\",\n",
        "    \"NVIDIA stock surges as demand for AI chips remains strong.\",\n",
        "    \"The firm announced a restructuring plan, sending shares lower.\",\n",
        "    \"Revenue growth slowed quarter-over-quarter, but profitability improved.\",\n",
        "    \"Investors remain cautious ahead of the Federal Reserve meeting.\",\n",
        "    \"Strong cash flow and reduced debt boosted investor confidence.\",\n",
        "    \"The outlook remains uncertain amid macroeconomic headwinds.\"\n",
        "]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "\n",
        "# optional: move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def predict_sentiment(text: str):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "    pred_id = out.logits.argmax(dim=-1).item()\n",
        "    return model.config.id2label[pred_id]\n",
        "\n",
        "for text in example_sentences:\n",
        "    label = predict_sentiment(text)\n",
        "    print(f\"{label.upper():8} | {text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "38f0b474",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ally Financial pulls outlook',\n",
              " 'Dell, HPE targets trimmed on compute headwinds',\n",
              " \"Moody's turns negative on Party City\",\n",
              " 'Deutsche Bank cuts to Hold',\n",
              " 'Compass Point cuts to Sell',\n",
              " 'Barclays cools on Molson Coors',\n",
              " 'Barclays cuts to Equal Weight',\n",
              " 'Analysts Eviscerate Musk\\'s Cybertruck: \"0% Of Responses Felt It Will Be A Success\"',\n",
              " 'Barclays assigns only a 20% chance that studies on a Gilead antiviral drug being done in China will succeed against‚Ä¶',\n",
              " \"BTIG points to breakfast pressure for Dunkin' Brands\",\n",
              " \"Children's Place downgraded to neutral from outperform at Wedbush, price target slashed to $60 from $130\",\n",
              " 'Clovis Oncology downgraded to in line from outperform at Evercore ISI',\n",
              " 'Downgrades 4/7: $AAN $BDN $BECN $BTE $CDEV $CHK $COOP $CPE $CVA $DAN $DOC $DRH $EPR $ESRT $ETM $FAST $FBM $GM $GMS‚Ä¶',\n",
              " \"Goldman pulls Progressive from Goldman's conviction list; shares -2.7%\",\n",
              " 'Hanesbrands downgraded to underperform vs. neutral at BofA Merrill Lynch',\n",
              " 'Intelsat cut to Market Perform at Raymond James',\n",
              " 'LendingTree price target cut to $350 from $400 at SunTrust Robinson Humphrey',\n",
              " 'Mizuho cuts XLNX target on near-term headwinds',\n",
              " 'MPLX cut at Credit Suisse on potential dilution from Marathon strategic review',\n",
              " 'Netflix downgraded to underperform at Wells Fargo',\n",
              " 'NortonLifeLock stock price target cut to $18 from $25 at Deutsche Bank',\n",
              " 'Norwegian Cruise stock price target cut to $48 from $55 at CFRA',\n",
              " 'Novus Therapeutics stock price target cut to $2.50 from $3.75 at Ascendiant Capital',\n",
              " 'Nutrien stock price target cut to $54 vs. $55 at BofA Merrill Lynch',\n",
              " 'Okta -2% on valuation downgrade',\n",
              " 'Solarworlds stock price target cut to $23 vs. $24 at Instinet',\n",
              " 'Trendforce cuts iPhone estimate after Foxconn delay',\n",
              " 'Wayfair price target lowered to $110 from $120 at Stifel, buy rating maintained',\n",
              " 'WWE stock price target cut to $58 from $92 at MKM Partners',\n",
              " 'as expected, keeps going higher. Cantor doubled its price target this morning to $4',\n",
              " 'CACI gains a bull on growth acceleration',\n",
              " 'CNH Industrial upped to Buy at Deutsche Bank on valuation',\n",
              " 'Devon Energy, Hess upgraded at J.P. Morgan on improved E&P outlook',\n",
              " \"Energizer shakes off JPMorgan's bear call\",\n",
              " 'Baird bullish on beat-up Canada Goose',\n",
              " 'BMO Capital joins Nike bull camp',\n",
              " 'Buy oil service firms, Bernstein says after seven-year bearish view',\n",
              " 'Goldman ups view on Henry Schein in premarket analyst action',\n",
              " 'Alliance Global Partners starts at Buy',\n",
              " 'Urban Outfitters stands out in mall sector - BofA',\n",
              " 'H.C. Wainwright starts at Buy',\n",
              " 'Adobe price target raised to $350 vs. $320 at Canaccord',\n",
              " 'AM Best Revises Outlooks to Positive for Pac√≠fico Compa√±√≠a de Seguros y Reaseguros S.A.',\n",
              " \"AMD +1.3% after Cowen's target lift\",\n",
              " 'Applied Materials, Inc. Reported Earnings Last Week And Analysts Are Already Upgrading Their Estimates',\n",
              " 'Arch Coal rated Buy at Benchmark, seeing opportunity after selloff',\n",
              " 'Autodesk stock price target raised to $162 from $149 at Wedbush',\n",
              " 'Avnet stock price target raised to $37 vs. $35 at SunTrust Robinson Humphrey',\n",
              " 'Boeing started at buy with $375 stock price target at Benchmark',\n",
              " \"BofA sees 'solid demand backdrop' for D.R. Horton in 2020\",\n",
              " 'Broadcom stock price target raised to $361 vs. $322 at SunTrust Robinson Humphrey',\n",
              " 'Cantor sees 19% upside in J&J in premarket analyst action',\n",
              " 'Champions Oncology started at speculative buy with $11 stock price target at Benchmark',\n",
              " 'Citi raises Alphabet on margin potential',\n",
              " 'Citigroup stock price target raised to $127 from $124 at Oppenheimer',\n",
              " 'ETF assets to surge tenfold in 10 years to $50 trillion, Bank of America predicts',\n",
              " 'GE upgraded from Sell by longtime bear',\n",
              " 'Goldman Sachs stock price target raised to $367 from $358 at Oppenheimer',\n",
              " 'GrubHub stock price target raised to $50 from $40 at Stifel Nicolaus',\n",
              " 'Halliburton started at buy with $26 stock price target at Deutsche Bank',\n",
              " 'Helen of Troy started at outperform with $210 stock price target at Oppenheimer',\n",
              " 'Highlight: Edward Jones Sr. Equity Analyst Jennifer Roland on ExxonMobil reducing 2020 Capex by 30%: ‚ÄúDefinitely a‚Ä¶',\n",
              " 'Humana stock price target raised to $370 from $350 at SunTrust RH',\n",
              " 'JMP Securities upgrades snap to outperform with $20 pt',\n",
              " 'Liberty Global PLC maintained as buy with $32 price target at Benchmark',\n",
              " 'Lululemon Athletica price target raised to $255 from $220 at CFRA',\n",
              " 'Lumentum initiated as positive at Susquehanna',\n",
              " 'Markel Corporation Beat Analyst Estimates: See What The Consensus Is Forecasting For Next Year',\n",
              " 'Mednax upgraded to buy from hold at Stifel, price target raised to $33 from $25',\n",
              " 'Model N upgraded to overweight from neutral at JPMorgan, price target raised to $36 from $30',\n",
              " 'Morgan Stanley sees GM doubling in bull case scenario',\n",
              " 'Motorola Solutions stock fair value estimate raised to $192 from $167 at MKM Partners',\n",
              " 'New for subscribers: Analysts continue to upgrade stocks like Tesla and eBay on hopes the rebound is for real‚Ä¶',\n",
              " 'Omnicell stock price target raised to $96 vs. $90 at Benchmark',\n",
              " 'Peloton bulls defend the upside case',\n",
              " 'Piper Jaffray analyst Erinn Murphy reiterated an Overweight rating and $44.00 price target on Crocs (NASDAQ: $CROX)‚Ä¶',\n",
              " 'Progyny started at overweight with $26 stock price target at J.P. Morgan',\n",
              " 'Snap Analyst Projects 37% Revenue Growth In 2020',\n",
              " 'Spirit Airlines stock price target raised to $55 from $49 at Deutsche Bank',\n",
              " 'State Street stock price target raised to $84 from $73 at Buckingham',\n",
              " \"Stock Market Update: AMD's price target raised to $47 at Cowen\",\n",
              " 'Synaptics stock price target raised to $76 from $60 at Susquehanna',\n",
              " 'TechnipFMC started at buy with $33 stock price target at Deutsche Bank',\n",
              " 'Tesla stock price target raised to $290 from $260 at Deutsche Bank',\n",
              " 'TJX stock price target raised to $70 from $62 at MKM Partners',\n",
              " 'Twitter upgraded to positive from neutral at Susquehanna',\n",
              " 'Uber stock price target raised to $42 from $31 at Susquehanna',\n",
              " 'Uber stock price target raised to $48 from $46 at HSBC Global',\n",
              " 'UBS Upgrades Hasbro As Stock Price Bakes In Tariffs, Slow Holiday',\n",
              " 'UnitedHealth stock price target raised to $335 from $310 at SunTrust RH',\n",
              " 'Vertex Pharmaceuticals stock price target raised to $245 from $235 at BofA Merrill Lynch',\n",
              " 'Xilinx stock price target raised to $97 vs. $94 at SunTrust Robinson Humphrey',\n",
              " 'AM Best Revises Outlooks to Stable for Sublimity Insurance Company',\n",
              " 'Analyst: Amazon Blocking FedEx Ground Good News For UPS',\n",
              " 'Analysts Expect Breakeven For China Online Education Group (NYSE:COE)',\n",
              " \"Crown Holdings, Inc. Full-Year Results: Here's What Analysts Are Forecasting For Next Year\",\n",
              " 'Here are the best analyst calls of the week on Wall Street including Disney and a satellite play',\n",
              " 'Little impact on Netflix from Disney Plus launch - Credit Suisse',\n",
              " \"Mitek bull calls pullback 'an overreaction'\",\n",
              " 'Peabody Energy started at hold at Benchmark',\n",
              " \"Skechers U.S.A., Inc. Annual Results: Here's What Analysts Are Forecasting For Next Year\",\n",
              " \"T. Boone Pickens' BP Capital Adds 3 Energy Stocks to Portfolio\",\n",
              " 'Tenable Holdings, Inc. Just Released Its Third-Quarter And Analysts Have Been Updating Their Estimates',\n",
              " 'Top Analyst Upgrades and Downgrades: Cardinal Health, Domino‚Äôs, FedEx, Ford, GE, Grubhub, HSBC, Marvell, Twitter, Uber and More',\n",
              " \"Tyson Foods, Inc. First-Quarter Results Just Came Out: Here's What Analysts Are Forecasting For Next Year\",\n",
              " 'Wayfair initiated as hold with $95 price target at SunTrust Robinson Humphrey',\n",
              " \"Central bank 'collateral damage' is skewing financial markets, one economist says\",\n",
              " 'China central bank warns high financial risks amid rising economic headwinds - Reuters',\n",
              " 'ECB data show eurozone banks had weak profits before coronavirus',\n",
              " \"Fed's Williams says U.S. economy is clearly facing several challenges\",\n",
              " \"Former Federal Reserve Chairman Ben Bernanke says he doesn't see a quick, sharp rebound in the economy after its pr‚Ä¶\",\n",
              " 'Jerome Powell comes close to acknowledging that the Federal Reserve may not have the firepower to fight the next re‚Ä¶',\n",
              " 'No, The Fed Won\\'t \"Save The Market\" - Here\\'s Why',\n",
              " '\"There is every reason to believe that the economic rebound, when it comes, can be robust,\" Fed Chair Jerome Powell‚Ä¶',\n",
              " 'Federal Reserve announces extensive new measures to support the economy',\n",
              " 'Commercial and industrial loans at all commercial banks climb by $105.8 billion to $2.845 trillion in the week endi‚Ä¶',\n",
              " 'Fed surprises market with program to support corporate bonds amid coronavirus pandemic',\n",
              " 'Highlight: The Fed has launched an unprecedented round of asset purchases. \"The idea here is the Federal Reserve is‚Ä¶',\n",
              " \"The World Bank plans to lend Uganda $1.9 billion to help finance the East African nation's budget deficit\",\n",
              " '\"We encourage families to explore virtual #financialliteracy resources. The Federal Reserve Bank of Richmond create‚Ä¶',\n",
              " 'Africa-Europe Alliance: Denmark provides \\x8010 million for sustainable development under the EU External Investment P‚Ä¶',\n",
              " \"Bank agencies announced they'll temporarily lower the community bank leverage ratio to 8%. The rule change -\\x9d requir‚Ä¶\",\n",
              " 'Bank of Ireland : Mortgage Bank - 7 KB #BankofIreland #Stock #MarketScreener',\n",
              " 'Bank of Jamaica 14-Day Repo Auction Announcement -24 February 2020 #Stock #MarketScreener',\n",
              " 'Bank of Jamaica 30-day CD Auction Press Release #economy #MarketScreener',\n",
              " 'Brazil economists forecast more rate cuts ahead',\n",
              " 'Buyback Backlash Begins: Fed Will Limit Buybacks & Dividends For Companies Using Its Credit Facility',\n",
              " 'Central Bank of Nigeria Communique No. 128 of the Monetary Policy Committee Meeting of Jan... #Stock‚Ä¶',\n",
              " 'Central banks don‚Äôt have as much monetary policy power as they used to, former BOE policy maker Ian McCafferty says',\n",
              " \"Cleveland Fed President Loretta Mester said the coronavirus outbreak is a threat to the economy but doesn't yet jus‚Ä¶\",\n",
              " 'Efforts to support the faltering economy could extend to some form of direct yield curve control. New‚Ä¶',\n",
              " \"Fed Chair Jay Powell grilled on China's cryptocurrency plans, US response by @readDanwrite\",\n",
              " 'Fed Chair Jerome Powell was chided by a Democratic lawmaker for his attendance at a party thrown by Amazon CEO Jeff‚Ä¶',\n",
              " 'Fed Chairman Jerome Powell puts lawmakers on notice that fiscal policy may need to play a bigger role countering do‚Ä¶',\n",
              " 'Fed minutes to tell a story',\n",
              " 'Fed Officials Weigh Risks Of Covid-19 -- Update #economy #MarketScreener',\n",
              " 'Fed President Loretta Mester due to speak in 5 minutes.',\n",
              " 'Fed removes reference to \"global developments\", has yet to blame global warming for repo crisis',\n",
              " 'Fed‚Äôs Rosengren Says Pursuing 2% Inflation Could Distort Markets',\n",
              " 'Federal Reserve Keeps Rates Steady and Sees Long Pause #currency #MarketScreener',\n",
              " 'Federal Reserve officials will feel comfortable maintaining their wait-and-see posture on interest rates after Frid‚Ä¶',\n",
              " \"Fed's 42-Day Repo 2x Oversubscribed In Scramble For Year End Liquidity\",\n",
              " \"Fed's Bullard said actions taken by the Fed and other authorities during this time period shouldn't be seen as stim‚Ä¶\",\n",
              " \"Fed's Mester says central bank can watch and wait on interest rates\",\n",
              " \"Fed's Rosengren backs 'patient' approach to any interest-rate moves\",\n",
              " \"Fed's Williams says rates are 'in the right place' but policy is not set in stone\",\n",
              " 'Global Risks to Extend Czech Rate Lockdown: Decision Day Guide',\n",
              " 'Heard on the Street: The Fed may need banks to lever up to absorb more activity, but it needs to do so in a way tha‚Ä¶',\n",
              " 'In the battle of central-bank stimulus bazookas, the Fed is winning out',\n",
              " 'In undertaking what will undoubtedly be its largest rescue effort ever, the Federal Reserve announced programs that‚Ä¶',\n",
              " \"Indonesia's central bank says the New York Federal Reserve will provide it with a $60 billion repurchase facility t‚Ä¶\",\n",
              " 'Italy may be willing to compromise on its holdout against a German plan for further integration of the EU‚Äôs banking‚Ä¶',\n",
              " 'LISTEN NOW: The Fed continues to make moves to combat the coronavirus crisis, including assuring limitless asset pu‚Ä¶',\n",
              " 'LIVE: Fed Chair Powell testifies before the Senate Banking Committee',\n",
              " 'Markets bet Fed is pushed to cut rates in coronavirus response',\n",
              " 'Minneapolis Fed chief Neel Kashkari says monetary policy can play the kind of redistributing role once thought to b‚Ä¶',\n",
              " 'Morocco is considering tapping at least part of a $2.97 billion liquidity line with the IMF as the coronavirus outb‚Ä¶',\n",
              " \"New Zealand central bank governor Adrian Orr may signal he's prepared to cut interest rates to cushion the economic...\",\n",
              " \"Norway's central bank governor says it's too early to reach any conclusions on the long term outlook for inflation\",\n",
              " 'Praet: ECB Needs Governments to Act',\n",
              " 'Rabobank: \"Fed\\'s Kashkari Has Just Come Out With A Jaw-Dropping Policy Shift\"',\n",
              " 'RBI May Cut Rates Later This Year, TS Lombard Says',\n",
              " 'RBI‚Äôs Long-Term Repo Operations Seen As Stealth Move To Bring Down Rates',\n",
              " 'Spain to guarantee up to 80% of SME bank loans to ease virus impact #economy #MarketScreener',\n",
              " \"The Bank of England's Financial Policy Committee says it's prepared to take further action as needed to help the fi‚Ä¶\",\n",
              " \"The Bank of England's Term Funding Scheme... #Stock #MarketScreener\",\n",
              " 'The Committee lowers the CBR to 7.25PC #Stock #MarketScreener',\n",
              " 'The consensus case for following the Fed is right, Ashok Bhatia of Neuberger Bergman tells @FerroTV‚Ä¶',\n",
              " \"The Fed mounted an extraordinary new array of programs to offset the 'severe disruptions' to the economy caused by‚Ä¶\",\n",
              " 'The Federal Reserve has launched an array of programs aimed at helping the markets and economy through the coronavi‚Ä¶',\n",
              " 'The Federal Reserve System includes 12 districts. Using those numbers, 1-12, is a handy way to learn about the cent‚Ä¶',\n",
              " 'The FRED Blog: Since the end of the Great Recession, market-based measures of long-run inflation expectations have‚Ä¶',\n",
              " \"The IMF may launch a new program that could back up the Federal Reserve's campaign to keep dollars flowing in the g‚Ä¶\",\n",
              " 'The Most Momentous Rate Decision This Month Isn‚Äôt at Fed or ECB',\n",
              " '-The U.K. will go into full lockdown to stymie the spread of coronavirus -The Fed offers to directly finance U.S. c‚Ä¶',\n",
              " 'Top economists say that the spread of the new coronavirus outbreak makes it more likely that the Federal Reserve wi‚Ä¶',\n",
              " 'Two crisis-veteran Federal Reserve officials said the central bank has plenty of room for more moves following a fl‚Ä¶',\n",
              " \"Two weeks later, no change, Fed ain't stopping the selling\",\n",
              " 'U.S. Fed preparing to buy new small business payroll loans: Wall Street Journal',\n",
              " 'UK starts first stage of 330 billion pound loan guarantee scheme',\n",
              " 'Zambia‚Äôs kwacha staged a comeback on Tuesday after the central bank raised the amount of funds that commercial lend‚Ä¶',\n",
              " 'Bank of America sees demand surge for paycheck protection loans',\n",
              " 'Honeywell says MAX production freeze to hurt 2020 sales growth',\n",
              " 'Africa retailer Jumia suspends e-commerce in Cameroon',\n",
              " 'Amazon blames holiday delivery delays on winter storms and high demand',\n",
              " 'Beckhams‚Äô business empire sees revenues drop 18%',\n",
              " 'BREAKING: FDA issues ban on some fruit and mint flavored vaping products',\n",
              " 'Bristol-Myers says trial of Opdivo plus Yervoy in melanoma treatment failed to meet main goal',\n",
              " 'Casino Operator Wynn Resorts Is Losing Up To $2.6 Million Per Day From Coronavirus Shutdown',\n",
              " 'China Solar Group Flags Raw Material, Labor Shortages on Virus',\n",
              " 'Fiat Chrysler Relies on Ram Growth as Europe Losses Mount',\n",
              " 'Ford recalls 262,000 pickup trucks with defective tailgate latches',\n",
              " 'Fox says cable ad revenue was hurt by impeachment coverage last quarter',\n",
              " 'ICYMI: Transport for London said Uber $UBER was not \"fit and proper\" to hold an operating license in London after a‚Ä¶',\n",
              " 'Jetstar to cut capacity by 10% in January as pilots take industrial action',\n",
              " \"Lowe's to shut 34 Canadian stores as it reports revenue miss\",\n",
              " \"Macy's says temporary issue with e-commerce business also impacted Q3 performance\",\n",
              " 'Mahindra Says Coronavirus May Jeopardize India Emissions Rollout',\n",
              " 'Major blockchain developer ConsenSys announces job losses #economy #MarketScreener',\n",
              " 'NTSB cites Uber, driver in fatal crash']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data Visualisation for Dataset\n",
        "test_ds = ds[\"validation\"]  # Use validation set for analysis\n",
        "\n",
        "test_ds[\"text\"][0:200]\n",
        "#ds2 = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
        "#ds2[\"validation\"][\"text\"][34]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ce67a413",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL INFERENCE WITHOUT SAEs\n",
            "============================================================\n",
            "\n",
            "üî¨ Running inference on 100 test samples...\n",
            "   Device: cuda\n",
            "   Model: ./finbert_twitter_ft/best\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|‚ñç         | 100/2388 [00:01<00:25, 91.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "‚úÖ INFERENCE COMPLETE (WITHOUT SAEs)\n",
            "============================================================\n",
            "   üìä Total Samples: 100\n",
            "   ‚úì Correct Predictions: 87\n",
            "   ‚úó Incorrect Predictions: 13\n",
            "   üéØ Model Accuracy: 87.00%\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Inference WITHOUT SAEs - Plain Model Accuracy on Test Data\n",
        "# import torch\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# from tqdm import tqdm\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL INFERENCE WITHOUT SAEs\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load the fine-tuned model\n",
        "save_dir = \"./finbert_twitter_ft/best\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Use validation set for evaluation\n",
        "test_ds = ds[\"validation\"]\n",
        "# MAX_SAMPLES = len(test_ds)  # Process all samples, or set a limit if needed\n",
        "MAX_SAMPLES = 100\n",
        "MAX_SEQ_LENGTH = 64\n",
        "\n",
        "print(f\"\\nüî¨ Running inference on {MAX_SAMPLES} test samples...\")\n",
        "print(f\"   Device: {device}\")\n",
        "print(f\"   Model: {save_dir}\\n\")\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# Process samples\n",
        "with torch.no_grad():\n",
        "    for idx, sample in enumerate(tqdm(test_ds, desc=\"Processing\")):\n",
        "        if idx >= MAX_SAMPLES:\n",
        "            break\n",
        "        \n",
        "        text = sample[\"text\"]\n",
        "        true_label = sample[\"label\"]\n",
        "        \n",
        "        # Tokenize with truncation\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_SEQ_LENGTH)\n",
        "        inputs = inputs.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        pred_id = outputs.logits.argmax(dim=-1).item()\n",
        "        \n",
        "        # Check if prediction is correct\n",
        "        if pred_id == true_label:\n",
        "            correct_predictions += 1\n",
        "        total_predictions += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"‚úÖ INFERENCE COMPLETE (WITHOUT SAEs)\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"   üìä Total Samples: {total_predictions}\")\n",
        "print(f\"   ‚úì Correct Predictions: {correct_predictions}\")\n",
        "print(f\"   ‚úó Incorrect Predictions: {total_predictions - correct_predictions}\")\n",
        "print(f\"   üéØ Model Accuracy: {accuracy:.2%}\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
